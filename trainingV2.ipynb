{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "654b901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier as rfc\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
    "\n",
    "from sklearn.linear_model import LinearRegression,ElasticNet,Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, KFold,RandomizedSearchCV\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,r2_score\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f090ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa0e725",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "# Create a custom logger\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "# Create handlers\n",
    "f_handler = logging.FileHandler('ModelTraining.log')\n",
    "\n",
    "# Create formatters and add it to handlers\n",
    "f_format = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "f_handler.setFormatter(f_format)\n",
    "# Set level of logging\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "# Add handlers to the logger\n",
    "logger.addHandler(f_handler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "217e2c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a398e99",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureEngineering:\n",
    "    '''\n",
    "    class FeatureEngineering walk on the row data to re arrange, handle missing data \n",
    "    and deal with outliers \n",
    "    '''\n",
    "    @staticmethod\n",
    "    def rearrange_features(df):\n",
    "        '''\n",
    "        this function to re format data \n",
    "        some values are not acceptable\n",
    "        some work of this function done in the data collector also, \n",
    "        when re formatiing number of bedrooms, baths, and re arrange amenities columns\n",
    "        '''\n",
    "        #drop all columns contain Unnamed in thier names\n",
    "        df = df.iloc[:, ~df.columns.str.contains('^Unnamed')]\n",
    "        # update the values in series of house price in df by replacing K\n",
    "        df.update(df[df['house_price'].str.contains('K')].iloc[:,0].str.replace('K','000'))\n",
    "        # after arranging amenities as columns, drop am column which contanins all amenities \n",
    "        df = df.drop(columns=['am'])\n",
    "        # change the type of values in the df\n",
    "        df=df.astype('int')\n",
    "        logger.info('data has been arranged in suitable format')\n",
    "        return df\n",
    "\n",
    "    \n",
    "    @staticmethod\n",
    "    def na_percentage_in_rows(df):\n",
    "        '''\n",
    "        This function search for missing values in Rows, \n",
    "        return a stat of all rows with missing values, \n",
    "        each row with its missing values percentage.  \n",
    "        '''\n",
    "        # get all index of rows that contain NaNs \n",
    "        is_NaN = df. isnull()\n",
    "        row_has_NaN = is_NaN. any(axis=1)\n",
    "        rows_with_NaN = df[row_has_NaN]\n",
    "\n",
    "        # create stat with rows index and its NaN value percentage\n",
    "        stat = pd.DataFrame()\n",
    "        stat['row'] = df[row_has_NaN].index\n",
    "        stat['na percentage'] = ((36-df[row_has_NaN].apply(lambda x: x.count(), axis=1))/36).tolist()\n",
    "        # return all index has a percentage of missing more than or equal 0.5 \n",
    "        logger.info('Index of rows which have missings values : {}'.format(df[row_has_NaN].index))\n",
    "        return stat,stat[stat['na percentage']>=0.5].iloc[:,0]\n",
    "    \n",
    "    @staticmethod\n",
    "    def na_percentage_in_cols(df):\n",
    "        '''\n",
    "        This function search for missing values in features, \n",
    "        return a stat of all columns with missing values, \n",
    "        each column with its missing values percentage. \n",
    "        '''\n",
    "        # create stat with columns and its NaN value percentage\n",
    "        stat =pd.DataFrame()\n",
    "        stat['col'] = df.columns\n",
    "        stat['na percentage']=df.isna().mean().tolist()\n",
    "        logger.info('features which have missings values : {}'.format(stat[stat['na percentage']>=0.5].iloc[:,0]))\n",
    "        # return all columns name has a percentage of missing more than or equal 0.5 \n",
    "        return stat,stat[stat['na percentage']>=0.5].iloc[:,0]\n",
    "\n",
    "    @staticmethod\n",
    "    def handle_missings(df):\n",
    "        '''\n",
    "        This function check the percentage of NaN values in rows and columns \n",
    "        and deside wether to drop them or not\n",
    "        '''\n",
    "        s1,index=FeatureEngineering.na_percentage_in_rows(df)\n",
    "        s2,features=FeatureEngineering.na_percentage_in_cols(df)\n",
    "        print(features)\n",
    "        # drop all index has a percentage of missing more than or equal 0.5\n",
    "        df = df.drop(index)\n",
    "        if features.size!=0:\n",
    "            df = df.drop(columns = [features])\n",
    "        logger.info('Missing data has been handled in dataframe')\n",
    "        return df\n",
    "\n",
    "\n",
    "\n",
    "    def drop_outliers(df,data_series):\n",
    "        '''\n",
    "        This function deals with outliers \n",
    "        this function will get the data and get rid of all outliers using IQR analysis\n",
    "        '''\n",
    "        # calculate Q1,Q3\n",
    "        Q1, Q3 = df[data_series].quantile([0.25, 0.75]).values\n",
    "        # IQR value\n",
    "        IQR = Q3 - Q1\n",
    "        # find limits of the data  \n",
    "        lower_limit = Q1 - 1.5 * IQR\n",
    "        upper_limit = Q3 + 1.5 * IQR\n",
    "\n",
    "        # finding index of all data outside the limits\n",
    "        s=df[data_series][( df[data_series] < lower_limit) |\n",
    "                          ( df[data_series] > upper_limit) ]\n",
    "        s.index\n",
    "        # drop data outside the limits\n",
    "        df = df.drop(s.index)\n",
    "        logger.info('Outliers Treatment')\n",
    "        return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f92c524d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaa668f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureSelection:\n",
    "    '''\n",
    "    Class FeatureSelection get important features that has a high correlation \n",
    "    with target variable.\n",
    "    '''\n",
    "    @staticmethod\n",
    "    def select_features(df, target_variable):\n",
    "        '''\n",
    "        This function selects important features using SelectFromModel library \n",
    "        '''\n",
    "        # split data into train and test\n",
    "        x = df.drop(target_variable, 1)\n",
    "        y = df[target_variable]\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.2,random_state=37)\n",
    "        \n",
    "        # random forest calssifier modelto use it in feature selection\n",
    "        model = rfc(n_estimators = 300, n_jobs = -1,random_state =37, min_samples_leaf = 50)\n",
    "        \n",
    "        # select from model with threashold 0.02, so select features with correlation more than 0.02 \n",
    "        sfm = SelectFromModel(model,threshold=0.02)\n",
    "        sfm.fit(x_train, y_train)\n",
    "        # get columns name of important features\n",
    "        selected_features = x_train.columns[(sfm.get_support())]\n",
    "        \n",
    "        # Creating a bar plot to show the selected features correlation and importance\n",
    "        font = {'size'   : 7}\n",
    "        matplotlib.rc('font', **font)\n",
    "        model.fit(x_train, y_train)\n",
    "        feature_imp = pd.Series(model.feature_importances_,index=x.columns.values).sort_values(ascending=False)\n",
    "        sns.barplot(x=feature_imp, y=feature_imp.index)\n",
    "        # Add labels to your graph\n",
    "        plt.xlabel('Feature Importance Score')\n",
    "        plt.ylabel('Features')\n",
    "        plt.title(\"Visualizing Important Features\")\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "        logger.info('the important features have been selected as : {}'.format(selected_features))\n",
    "        # return the name of the important features\n",
    "        return selected_features\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fd9362",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f4111e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataSplitter:\n",
    "    '''\n",
    "    Class dataSplitter to split data into train and test using selected features \n",
    "    '''\n",
    "    def __init__(self,df,target_variable,selected_feat):\n",
    "        #self.x = df.drop(target_variable, 1)\n",
    "        self.x = df[selected_feat]\n",
    "        self.y = df[target_variable]\n",
    "        self.x_train, self.x_test, self.y_train, self.y_test = train_test_split(self.x,self.y,test_size=0.2,random_state=37)\n",
    "    \n",
    "    def scale_features(self):\n",
    "        '''\n",
    "        This function scale features usinf standardization \n",
    "        to have values of features between 1 and -1  \n",
    "        '''\n",
    "        pipeline = Pipeline([\n",
    "            ('std_scalar', StandardScaler())\n",
    "        ])\n",
    "\n",
    "        # standardize x_train, x_test\n",
    "        self.x_train = pipeline.fit_transform(self.x_train)\n",
    "        self.x_test = pipeline.transform(self.x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b29876",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcbc8345",
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class Model(ABC):\n",
    "\n",
    "    '''\n",
    "    Class Model have all validation and evaluation methods with save method\n",
    "    '''\n",
    "    def __init__(self, data, dataTune):\n",
    "        # results of all metrics for all models\n",
    "        self.results_df = pd.DataFrame()\n",
    "        # data to use in training \n",
    "        self.data = data\n",
    "        # data to use in hyper tuning \n",
    "        self.dataTune = dataTune\n",
    "        self.model = \"\"\n",
    "        \n",
    "    @abstractmethod\n",
    "    def train(self):\n",
    "        pass\n",
    "        \n",
    "    def cross_val(self):\n",
    "        '''\n",
    "        This function calculate cross_val_score for model\n",
    "        '''\n",
    "        cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "        # evaluate model\n",
    "        pred = cross_val_score(self.model, self.data.x_test,self.data.y_test,cv=cv)\n",
    "        logger.info('cross_val_score: {}'.format(pred.mean()))\n",
    "        return pred.mean()\n",
    "\n",
    "\n",
    "\n",
    "    def print_evaluate(self,true, predicted):  \n",
    "        '''\n",
    "        printing evaluation metrics\n",
    "        '''\n",
    "        mae, mse, rmse, r2_square=self.evaluate(true, predicted)\n",
    "        logger.info('MAE: {}'.format(mae))\n",
    "        logger.info('MSE: {}'.format(mse))\n",
    "        logger.info('RMSE: {}'.format(rmse))\n",
    "        logger.info('R2 Square: {}'.format(r2_square))\n",
    "        logger.info('__________________________________')\n",
    "        \n",
    "        print('MAE:', mae)\n",
    "        print('MSE:', mse)\n",
    "        print('RMSE:', rmse)\n",
    "        print('R2 Square', r2_square)\n",
    "        print('__________________________________')\n",
    "\n",
    "\n",
    "    def evaluate(self, predicted):\n",
    "        '''\n",
    "        calculate evaluation metrics for a model\n",
    "        '''\n",
    "        mae = mean_absolute_error(self.data.y_test, predicted)\n",
    "        mse = mean_squared_error(self.data.y_test, predicted)\n",
    "        rmse = np.sqrt(mean_squared_error(self.data.y_test, predicted))\n",
    "        r2_square = r2_score(self.data.y_test, predicted)\n",
    "        return mae, mse, rmse, r2_square   \n",
    "    \n",
    "    def predict(self,x,y):\n",
    "        '''function to use trained model to do predictions'''\n",
    "        '''\n",
    "        x: data\n",
    "        y: label \n",
    "        '''\n",
    "        pred_y = self.model.predict(x)\n",
    "        self.print_evaluate(y,pred_y)\n",
    "        df = pd.DataFrame()\n",
    "        df['True'] = y.tolist()\n",
    "        df['Prediction'] = pred_y.tolist()\n",
    "        logger.info('Prediction: {}'.format(df))\n",
    "        return df\n",
    "    \n",
    "    def SaveModel(self,filename='finalized_model.sav'):\n",
    "        # Save the model as a pickle in a file\n",
    "        # save the model to disk\n",
    "        pickle.dump(self.model, open(filename, 'wb'))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0f35687",
   "metadata": {},
   "outputs": [],
   "source": [
    "class linearReg(Model):\n",
    "    def train(self):\n",
    "        ''' to train a linear regression model'''\n",
    "        logger.info('Training linear regression model')\n",
    "        # define object of linear regression model\n",
    "        self.model = LinearRegression(normalize=False)\n",
    "        # train the model\n",
    "        self.model.fit(self.data.x_train,self.data.y_train)\n",
    "        # predict \n",
    "        test_pred = self.model.predict(self.data.x_test)\n",
    "        train_pred = self.model.predict(self.data.x_train)\n",
    "        \n",
    "        # recording metric evaluation \n",
    "        print('Test dataset evaluation:\\n_____________________________________')\n",
    "        self.print_evaluate(self.data.y_test, test_pred)\n",
    "        print('Train dataset evaluation:\\n_____________________________________')\n",
    "        self.print_evaluate(self.data.y_train, train_pred)\n",
    "        \n",
    "        # add all metrics data to a dataframe results_df\n",
    "        self.results_df = pd.DataFrame(data=[[\"Linear Regression\", *self.evaluate(test_pred) , self.cross_val()]], \n",
    "                          columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "        # save the model \n",
    "        self.SaveModel('LinReg.sav')\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ac0a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "##################### Random Forest Regressor#########################   \n",
    "class RandomForest(Model):\n",
    "    def train(self):\n",
    "        ''' train a Random Forest Regressor model'''\n",
    "        logger.info('Training Random Forest Regressor model')\n",
    "        # get the best hypertuned model for Random Forest Regressor\n",
    "        self.model = self.HyperTuneRandomForest()\n",
    "        # train model\n",
    "        self.model.fit(self.data.x_train, self.data.y_train)\n",
    "        # predictions\n",
    "        test_pred = self.model.predict(self.data.x_test)\n",
    "        train_pred = self.model.predict(self.data.x_train)\n",
    "        # recording evaluation metrics\n",
    "        print('Test set evaluation:\\n_____________________________________')\n",
    "        self.print_evaluate(self.data.y_test, test_pred)\n",
    "        print('Train set evaluation:\\n_____________________________________')\n",
    "        self.print_evaluate(self.data.y_train, train_pred)\n",
    "        # add all metrics data to a dataframe results_df\n",
    "        self.results_df = pd.DataFrame(data=[[\"Random Forest Regressor\", *self.evaluate(test_pred), self.cross_val()]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
    "        #save model\n",
    "        self.SaveModel('RandForest.sav')\n",
    "        \n",
    "    \n",
    "    def HyperTuneRandomForest(self):\n",
    "        '''Random Forest Regressor hyper parameters tuning'''\n",
    "        # Number of trees in random forest\n",
    "        n_estimators = [int(x) for x in np.linspace(start = 200, stop = 2000, num = 10)]\n",
    "        # Number of features to consider at every split\n",
    "        max_features = ['auto', 'sqrt']\n",
    "        # Maximum number of levels in tree\n",
    "        max_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\n",
    "        max_depth.append(None)\n",
    "        # Minimum number of samples required to split a node\n",
    "        min_samples_split = [2, 5, 10]\n",
    "        # Minimum number of samples required at each leaf node\n",
    "        min_samples_leaf = [1, 2, 4]\n",
    "        # Method of selecting samples for training each tree\n",
    "        bootstrap = [True, False]\n",
    "        # Create the random grid\n",
    "        random_grid = {'n_estimators': n_estimators,\n",
    "                       'max_features': max_features,\n",
    "                       'max_depth': max_depth,\n",
    "                       'min_samples_split': min_samples_split,\n",
    "                       'min_samples_leaf': min_samples_leaf,\n",
    "                       'bootstrap': bootstrap}\n",
    "        # defin object of RandomForestRegressor to hyper tune the parameter\n",
    "        rf = RandomForestRegressor()\n",
    "        # Random search of parameters, using 3 fold cross validation, \n",
    "        # search across 100 different combinations, and use all available cores\n",
    "        rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "        # Fit the random search model\n",
    "        rf_random.fit(self.dataTune.x_train, self.dataTune.y_train)\n",
    "        logger.info('best param for: {}'.format(rf_random.best_params_))\n",
    "        return rf_random.best_estimator_\n",
    "    \n",
    "###################### Gradient Boosting Regressor ####################\n",
    "class GradientBoosting\n",
    "    def train(self):\n",
    "        '''Training Gradient Boosting Regressor model'''\n",
    "        logger.info('Training Gradient Boosting Regressor model')\n",
    "        # get the best model of Gradient Boosting Regressor after hyper parameters tuning\n",
    "        self.model = self.HyperTuneGradientBoosting()\n",
    "        # train the model\n",
    "        model.fit(self.data.x_train, self.data.y_train)\n",
    "        # prediction\n",
    "        test_pred = self.model.predict(self.data.x_test)\n",
    "        train_pred = self.model.predict(self.data.x_train)\n",
    "        # recording evaluation metrics\n",
    "        print('Test dataset evaluation:\\n_____________________________________')\n",
    "        self.print_evaluate(self.data.y_test, test_pred)\n",
    "        print('Train dataset evaluation:\\n_____________________________________')\n",
    "        self.print_evaluate(self.data.y_train, train_pred)\n",
    "        # add all metrics data to a dataframe results_df\n",
    "        self.results_df = pd.DataFrame(data=[[\"Gradient Boosting Regressor\", *self.evaluate( test_pred), self.cross_val()]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
    "        \n",
    "        # save model\n",
    "        self.SaveModel('GradBoost.sav')\n",
    "        \n",
    "    \n",
    "    def HyperTuneGradientBoosting(self):\n",
    "        '''Gradient Boosting Regressor hyper parameters tuning'''\n",
    "        # hyper parameters\n",
    "        params = {'n_estimators':[500, 1000, 1500, 2000], 'max_depth':[3, 5, 8],'random_state':[22,37,50]}\n",
    "        # define object of GradientBoostingRegressor model\n",
    "        gbr = GradientBoostingRegressor()\n",
    "        # create GridSearchCV object to search for the best estimator\n",
    "        gbr_grid = GridSearchCV(gbr, params, cv=5)\n",
    "        gbr_grid.fit(self.dataTune.x_train, self.dataTune.y_train)\n",
    "        logger.info('best param for: {}'.format(gbr_grid.best_params_))\n",
    "        return gbr_grid.best_estimator_\n",
    "    \n",
    "#################### ElasticNet ####################\n",
    "class ElasticNet(Model):\n",
    "    def train(self):\n",
    "        '''Training ElasticNet model'''\n",
    "        logger.info('Training ElasticNet model')\n",
    "        # hyperparameters to be tuned\n",
    "        elastic_params = {'alpha':np.arange(0, 1, 0.01)}\n",
    "        # hyperparameters tuning using GridSearchCV\n",
    "        best_estim = GridSearchCV(ElasticNet(), param_grid=elastic_params).fit(self.dataTune.x_train, self.dataTune.y_train).best_estimator_\n",
    "        # get the best model of ElasticNet after hyperparameters tuning using GridSearchCV\n",
    "        self.model = best_estim\n",
    "        # train the model\n",
    "        self.model.fit(self.data.x_train, self.data.y_train)\n",
    "\n",
    "        test_pred = self.model.predict(self.data.x_test)\n",
    "        train_pred = self.model.predict(self.data.x_train)\n",
    "        # recording evaluation metrics\n",
    "        print('Test set evaluation:\\n_____________________________________')\n",
    "        self.print_evaluate(self.data.y_test, test_pred)\n",
    "        print('Train set evaluation:\\n_____________________________________')\n",
    "        self.print_evaluate(self.data.y_train, train_pred)\n",
    "        # add all metrics data to a dataframe results_df\n",
    "        self.results_df = pd.DataFrame(data=[[\"ElasticNet Regressor\", *self.evaluate(test_pred), self.cross_val()]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
    "        #save model\n",
    "        self.SaveModel('Elastic.sav')\n",
    "\n",
    "##################### Lasso ####################\n",
    "class Lasso(Model):\n",
    "    def train(self): \n",
    "        '''Training Lasso model'''\n",
    "        logger.info('Training Lasso model')\n",
    "        # hyperparameters to be tuned\n",
    "        lasso_params = {'alpha':np.arange(0, 1, 0.01)}\n",
    "        # hyperparameters tuning using GridSearchCV\n",
    "        best_estim = GridSearchCV(Lasso(), param_grid=lasso_params).fit(self.dataTune.x_train, self.dataTune.y_train).best_estimator_\n",
    "        # get the best model of Lasso after hyperparameters tuning using GridSearchCV\n",
    "        self.model = best_estim\n",
    "        # train the model\n",
    "        self.model.fit(self.data.x_train, self.data.y_train)\n",
    "\n",
    "        test_pred = self.model.predict(self.data.x_test)\n",
    "        train_pred = self.model.predict(self.data.x_train)\n",
    "        # recording evaluation metrics\n",
    "        print('Test set evaluation:\\n_____________________________________')\n",
    "        self.print_evaluate(self.data.y_test, test_pred)\n",
    "        print('Train set evaluation:\\n_____________________________________')\n",
    "        self.print_evaluate(self.data.y_train, train_pred)\n",
    "        # add all metrics data to a dataframe results_df\n",
    "        results_df = pd.DataFrame(data=[[\"Lasso Regressor\", *self.evaluate(test_pred), self.cross_val()]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
    "        # save model\n",
    "        self.SaveModel('Lasso.sav')\n",
    "        \n",
    "    \n",
    "##################### Ridge ####################\n",
    "class Ridge(Model):\n",
    "    def train(self):\n",
    "        '''Training Ridge model'''\n",
    "        logger.info('Training Ridge model')\n",
    "        # hyperparameters to be tuned\n",
    "        ridge_params = {'alpha':[200, 230, 250,265, 270, 275, 290, 300, 500]}\n",
    "        # hyperparameters tuning using GridSearchCV\n",
    "        best_estim = GridSearchCV(Ridge(), param_grid=ridge_params).fit(self.dataTune.x_train, self.dataTune.y_train).best_estimator_\n",
    "        # get the best model of Ridge after hyperparameters tuning using GridSearchCV\n",
    "        self.model = best_estim\n",
    "        # train model\n",
    "        self.model.fit(self.data.x_train, self.data.y_train)\n",
    "\n",
    "        test_pred = self.model.predict(self.data.x_test)\n",
    "        train_pred = self.model.predict(self.data.x_train)\n",
    "        # recording evaluation metrics\n",
    "        print('Test set evaluation:\\n_____________________________________')\n",
    "        self.print_evaluate(self.data.y_test, test_pred)\n",
    "        print('Train set evaluation:\\n_____________________________________')\n",
    "        self.print_evaluate(self.data.y_train, train_pred)\n",
    "        # add all metrics data to a dataframe results_df\n",
    "        self.results_df = pd.DataFrame(data=[[\"Ridge Regression\", *self.evaluate( test_pred), self.cross_val()]], \n",
    "                                    columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\n",
    "        # save model\n",
    "        self.SaveModel('Ridge.sav')\n",
    "        \n",
    "\n",
    "##################### KNN ####################\n",
    "class KNN(Model):\n",
    "    def train(self):\n",
    "        '''Training KNeighbors Regressor model'''\n",
    "        logger.info('Training KNeighbors Regressor model')\n",
    "        # Define hyperparameters\n",
    "        hp_params = {'n_neighbors': [100,200,300], 'weights': ['uniform','distance']}\n",
    "        \n",
    "        # Search for best hyperparameters and get the best estimator\n",
    "        knr = GridSearchCV(estimator= KNeighborsRegressor(), param_grid=hp_params, scoring='r2').fit(self.dataTune.x_train, self.dataTune.y_train).best_estimator_\n",
    "        # get the best model of Ridge after hyperparameters tuning using GridSearchCV\n",
    "        self.model = knr\n",
    "        # ttrain model\n",
    "        self.model.fit(self.data.x_train, self.data.y_train)\n",
    "        \n",
    "        test_pred = self.model.predict(self.data.x_test)\n",
    "        train_pred = self.model.predict(self.data.x_train)\n",
    "        # recording evaluation metrics\n",
    "        print('Test set evaluation:\\n_____________________________________')\n",
    "        self.print_evaluate(self.data.y_test, test_pred)\n",
    "        print('Train set evaluation:\\n_____________________________________')\n",
    "        self.print_evaluate(self.data.y_train, train_pred)\n",
    "        # add all metrics data to a dataframe results_df\n",
    "        results_df = pd.DataFrame(data=[[\"KNeighbors Regressor\", *self.evaluate( test_pred), self.cross_val()]], \n",
    "                            columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', 'Cross Validation'])\n",
    "        # save model\n",
    "        self.SaveModel('KNR.sav')\n",
    "           \n",
    "#######################################################    \n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28fff3d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97771ae",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa7fd74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
